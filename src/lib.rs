/*!
Это дополнение предоставляет процедуры для поиска строк для совпадений с регулярным выражением (т. н. «regex»). 
Правила писания регулярных выражений, поддерживаемые этим дополнением, похожи на правила писания других движков регулярных выражений, 
но в нем отсутствуют несколько функций, которые неизвестно, как правильно использовать. Это включает в себя, помимо прочего, 
просмотр и обратные ссылки. Взамен все поиски регулярных выражений в этом дополнении имеют наихудшую
`O(m * n)` временную сложность, где `m` соответствует регулярному выражению и `n` 
соответствует искомой строки.

[regular expression]: https://en.wikipedia.org/wiki/Regular_expression

Если вам нужно только руководство API, то переходите к  [`Regex`] виду. В противном случае, вот краткий пример, 
показывающий один из способов разбора вывода программы, похожей на grep:

```rust
use regex::Regex;

let re = Regex::new(r"(?m)^([^:]+):([0-9]+):(.+)$").unwrap();
let hay = "\
path/to/foo:54:Blue Harvest
path/to/bar:90:Something, Something, Something, Dark Side
path/to/baz:3:It's a Trap!
";

let mut results = vec![];
for (_, [path, lineno, line]) in re.captures_iter(hay).map(|c| c.extract()) {
    results.push((path, lineno.parse::<u64>()?, line));
}
assert_eq!(results, vec![
    ("path/to/foo", 54, "Blue Harvest"),
    ("path/to/bar", 90, "Something, Something, Something, Dark Side"),
    ("path/to/baz", 3, "It's a Trap!"),
]);
# Ok::<(), Box<dyn std::error::Error>>(())
```

# Обзор

Простейший вид данных [`Regex`] в составе данного дополнения. Его наиболее часто используемые способы:  <br>

* [`Regex::new`] собирает Регулярное выражение, используя настройку по умолчанию. 
* [`RegexBuilder`] позволяет задать настройку, отличную от настройки по умолчанию. (Например, соответствие без учета заглавных или строчных букв, подробный режим и другие.)
* [`Regex::is_match`] сообщает, есть ли совпадение в определенном стоге сена.
* [`Regex::find`] сообщает смещения байтов совпадения в стоге сена, если таковое существует.
* [`Regex::find_iter`] возвращает повторитель по всем таким совпадениям.
* [`Regex::captures`] возвращает [`Captures`],  который сообщает как смещения байтов совпадения в стоге сена, 
так и смещения байтов каждой совпадающей группы захвата из регулярного выражения в стоге сена.
* [`Regex::captures_iter`] возвращает повторитель по всем таким совпадениям.

Также есть [`RegexSet`], который позволяет искать несколько образцов регулярных выражений одновременно в одном поиске. 
Однако в настоящее время он сообщает только о совпадающих образцах, а не о смещениях байтов совпадения.

В противном случае это руководство по дополнению верхнего уровня представлено следующим образом:

* [Использование](#Использование)  показывает, как добавить дополнение `regex` в ваше дело Ржавчины.
* [Примеры](#Примеры) содержат ограниченный выбор примеров поиска с использованием регулярных выражений.
* [В разделе «Производительность»](#Производительность) дается краткий обзор того, как увеличить скорость поиска с помощью регулярных выражений.
* [Unicode](#unicode) рассматривает поддержку не-ASCII-образцов.
* [Правила написания](#Правила_написания) принятые для регулярных выражений, поддерживаемые этим дополнением в Ржавчине.
* [В разделе «Ненадежные входные данные»](#Ненадежный_ввод) рассматривается, как это дополнение справляется с образцами регулярных 
выражений или стогами сена, которые не являются надежными.
* [В разделе «Возможности дополнения»](#Возможности_дополнения) описываются возможности дополнения, которые можно включить или отключить для этого дополнения.
* [Другие дополнения](#Другие_дополнения) связаны с другими дополнениями в `regex` семействе.

# Использование

Дополнение `regex` находится на [crates.io](https://crates.io/crates/regex) и может быть использовано путем добавления `regex` 
к вашим зависимостям в вашем деле `Cargo.toml`.
Или, проще говоря, просто запустите приказ `cargo add regex`.

Вот полный пример, который создает новое дело в Ржавчине, добавляет зависимость от `regex`,  
создает исходную рукопись для поиска по регулярному выражению, а затем запускает программу.

Сначала создайте дело в новой папке:

```text
$ mkdir regex-example
$ cd regex-example
$ cargo init
```

Во-вторых, добавьте зависимость от `regex``:

```text
$ cargo add regex
```

В-третьих, внесите изменения в `src/main.rs``. Удалите то, что там есть, и замените это на это:

```
use regex::Regex;

fn main() {
    let re = Regex::new(r"Hello (?<name>\w+)!").unwrap();
    let Some(caps) = re.captures("Hello Murphy!") else {
        println!("no match!");
        return;
    };
    println!("The name is: {}", &caps["name"]);
}
```

В-четвертых, запустите его с помощью `cargo run`:

```text
$ cargo run
   Compiling memchr v2.5.0
   Compiling regex-syntax v0.7.1
   Compiling aho-corasick v1.0.1
   Compiling regex v1.8.1
   Compiling regex-example v0.1.0 (/tmp/regex-example)
    Finished dev [unoptimized + debuginfo] target(s) in 4.22s
     Running `target/debug/regex-example`
The name is: Murphy
```

При первом запуске программы будет показан более подробный вывод, как указано выше. 
Но при последующих запусках не придется пересобирать зависимости.

# Примеры 

В этом разделе приведены несколько примеров в виде руководства, показывающих, как искать в стоге сена с помощью регулярного выражения. В руководстве API есть еще примеры.

Однако прежде чем начать, стоит определить несколько понятий:

**regex** - это вид данных в Ржавчине, подвид которого `Regex`. Мы используем `re` 
в качестве имени переменной для регулярного выражения.<br>
**Образец (pattern)** - это строка, которая используется для построения регулярного выражения. Мы используем `pat` 
в качестве имени переменной для образца.<br>
**Стог сена (haystack)**  - это строка, которую ищет регулярное выражение. Мы используем `hay` 
в качестве имени переменной для haystack.<br>

Иногда слова «регулярное выражение» и «образец» используются как взаимозаменяемые.

Обычное использование регулярных выражений в этом дополнении осуществляется путем сборки
**образца (pattern)** в **regex**, а затем использования этого регулярного выражения для поиска, разделения 
или замены частей **стога сена (haystack)**.

### Пример: найти начальную букву отчества

Начнем с очень простого примера: регулярное выражение, которое ищет определенное имя, но использует подстановочный знак для сопоставления 
с инициалом среднего имени. Наш образец служит чем-то вроде образца, который будет сопоставлять определенное имя с любым инициалом среднего имени.

```rust
use regex::Regex;

// We use 'unwrap()' here because it would be a bug in our program if the
// pattern failed to compile to a regex. Panicking in the presence of a bug
// is okay.
let re = Regex::new(r"Homer (.)\. Simpson").unwrap();
let hay = "Homer J. Simpson";
let Some(caps) = re.captures(hay) else { return };
assert_eq!("J", &caps[1]);
```

В нашем первом примере стоит обратить внимание на несколько особенностей:
* Это `.` особый метазнак образца, который означает «соответствует любому одиночному знаку, за исключением новых строк». 
(Точнее, в этом дополнении это означает «соответствует любому исполнению UTF-8 любого одиночного знака Unicode, отличного от `\n`).
* Мы можем сопоставить любой знак `.` буквально, экранировав его, т. е `\.`.
* Мы используем необработанные [строки в Ржавчине] , чтобы избежать необходимости иметь дело с escape-последовательностями как в правилах написания образца 
регулярных выражений, так и в правилах написания строковых знаков в Ржавчине. Если бы мы не использовали здесь необработанные строки, нам пришлось бы использовать 
`\\.` для сопоставления знака `.`. То есть `r"\."` и `"\\."` являются равноценными образцами.
* Мы заключаем наше подстановочное `.` указание в скобки. Эти скобки имеют особое значение, которое говорит: «сделать любую часть стога сена, соответствующую этим скобкам, 
доступной в качестве группы захвата». После нахождения соответствия, мы получаем доступ к этой группе захвата с помощью `&caps[1]`.


[строки в Ржавчине]: https://doc.rust-lang.org/stable/reference/tokens.html#raw-string-literals

В противном случае, мы выполняем поиск с использованием `re.captures(hay)`, и возвращаемся из нашей функции, если совпадений не обнаружено. 
Затем мы ссылаемся на отчество, запрашивая часть стога сена, которая соответствует `1` группе захвата. 
(Группа захвата с индексом 0 неявная и всегда соответствует всему совпадению. В данном случае это `Homer J. Simpson`.)

### Пример: именованные группы захвата

Продолжая наш пример с инициалом отчества, приведенный выше, мы можем немного изменить образец, чтобы дать группе название, соответствующее инициалу отчества:

```rust
use regex::Regex;

// Note that (?P<middle>.) is a different way to spell the same thing.
let re = Regex::new(r"Homer (?<middle>.)\. Simpson").unwrap();
let hay = "Homer J. Simpson";
let Some(caps) = re.captures(hay) else { return };
assert_eq!("J", &caps["middle"]);
```

Присвоение имени группе может быть полезным, когда в образце есть несколько групп. Это делает рукопись, ссылающуюся на эти группы, немного более понятным.

### Пример: проверка определенной разметке даты

В этом примере показано, как проверить, соответствует ли стог сена в целом определенной разметке даты:

```rust
use regex::Regex;

let re = Regex::new(r"^\d{4}-\d{2}-\d{2}$").unwrap();
assert!(re.is_match("2010-03-14"));
```

Обратите внимание на использование якорей `^` и `$`. В этом дополнении каждый поиск по регулярному выражению 
выполняется с неявным `(?s:.)*?` в начале его образца, что позволяет регулярному выражению сопоставляться 
с любым местом в стоге сена. Якоря, как и выше, можно использовать для обеспечения соответствия всего стога сена образцу.

Это дополнение также поддерживает Unicode по умолчанию, что означает, что он `\d` может соответствовать большему 
количеству знаков, чем вы могли бы ожидать. Например:

```rust
use regex::Regex;

let re = Regex::new(r"^\d{4}-\d{2}-\d{2}$").unwrap();
assert!(re.is_match("𝟚𝟘𝟙𝟘-𝟘𝟛-𝟙𝟜"));
```

Чтобы сопоставить только десятичную цифру ASCII, все следующие условия одинаковы:

* `[0-9]`
* `(?-u:\d)`
* `[[:digit:]]`
* `[\d&&\p{ascii}]`

### Пример: поиск дат в стоге сена

В предыдущем примере мы показали, как можно проверить, что стог сена в целом соответствует определенной 
разметке даты. Но что, если мы хотим извлечь из стога сена все, что выглядит как даты в определенном виде? Для этого 
мы можем использовать API повторителя, чтобы найти все совпадения (обратите внимание, что мы удалили якоря и переключились на поиск цифр, содержащих только ASCII):

```rust
use regex::Regex;

let re = Regex::new(r"[0-9]{4}-[0-9]{2}-[0-9]{2}").unwrap();
let hay = "What do 1865-04-14, 1881-07-02, 1901-09-06 and 1963-11-22 have in common?";
// 'm' is a 'Match', and 'as_str()' returns the matching part of the haystack.
let dates: Vec<&str> = re.find_iter(hay).map(|m| m.as_str()).collect();
assert_eq!(dates, vec![
    "1865-04-14",
    "1881-07-02",
    "1901-09-06",
    "1963-11-22",
]);
```

Мы также можем перебирать  [`Captures`] значения вместо [`Match`] значений, и это, в свою очередь, 
позволяет получить доступ к каждому компоненту даты через захватывающие группы:

```rust
use regex::Regex;

let re = Regex::new(r"(?<y>[0-9]{4})-(?<m>[0-9]{2})-(?<d>[0-9]{2})").unwrap();
let hay = "What do 1865-04-14, 1881-07-02, 1901-09-06 and 1963-11-22 have in common?";
// 'm' is a 'Match', and 'as_str()' returns the matching part of the haystack.
let dates: Vec<(&str, &str, &str)> = re.captures_iter(hay).map(|caps| {
    // The unwraps are okay because every capture group must match if the whole
    // regex matches, and in this context, we know we have a match.
    //
    // Note that we use `caps.name("y").unwrap().as_str()` instead of
    // `&caps["y"]` because the lifetime of the former is the same as the
    // lifetime of `hay` above, but the lifetime of the latter is tied to the
    // lifetime of `caps` due to how the `Index` trait is defined.
    let year = caps.name("y").unwrap().as_str();
    let month = caps.name("m").unwrap().as_str();
    let day = caps.name("d").unwrap().as_str();
    (year, month, day)
}).collect();
assert_eq!(dates, vec![
    ("1865", "04", "14"),
    ("1881", "07", "02"),
    ("1901", "09", "06"),
    ("1963", "11", "22"),
]);
```

### Пример: более простое извлечение группы захвата

В этом случае можно использовать [`Captures::extract`] рукопись из предыдущего примера, чтобы немного упростить её:

```rust
use regex::Regex;

let re = Regex::new(r"([0-9]{4})-([0-9]{2})-([0-9]{2})").unwrap();
let hay = "What do 1865-04-14, 1881-07-02, 1901-09-06 and 1963-11-22 have in common?";
let dates: Vec<(&str, &str, &str)> = re.captures_iter(hay).map(|caps| {
    let (_, [year, month, day]) = caps.extract();
    (year, month, day)
}).collect();
assert_eq!(dates, vec![
    ("1865", "04", "14"),
    ("1881", "07", "02"),
    ("1901", "09", "06"),
    ("1963", "11", "22"),
]);
```

`Captures::extract` работает, заверяя, что количество соответствующих групп соответствует количеству групп, 
запрошенных через `[year, month, day]` правила писания. Если это так, то подстроки для каждой соответствующей группы 
захвата самостоятельно возвращаются в массиве соответствующего размера. Правила писания в Ржавчине для массивов сопоставления 
с образцом делает все остальное.

### Пример: замена на именованные группы захвата


Основываясь на предыдущем примере, возможно, мы хотели бы переупорядочить виды дат. 
Это можно сделать, найдя каждое совпадение и заменив его чем-то другим. Процедура 
[`Regex::replace_all`] предоставляет удобный способ сделать это, в том числе поддерживая 
ссылки на именованные группы в строке замены:

```rust
use regex::Regex;

let re = Regex::new(r"(?<y>\d{4})-(?<m>\d{2})-(?<d>\d{2})").unwrap();
let before = "1973-01-05, 1975-08-25 and 1980-10-18";
let after = re.replace_all(before, "$m/$d/$y");
assert_eq!(after, "01/05/1973, 08/25/1975 and 10/18/1980");
```
Способы замены на самом деле многообразны в замене, что обеспечивает большую гибкость, чем здесь. 
([`Regex::replace`]  Более подробные сведения см. в руководстве.)


### Пример: подробный режим

Когда ваше регулярное выражение становится сложным, вы можете рассмотреть возможность использования 
чего-то другого, кроме регулярного выражения. Но если вы придерживаетесь регулярного выражения, 
вы можете использовать `x` условие для включения режима незначимых пробелов или «подробного режима». 
В этом режиме пробелы считаются незначимыми, и можно писать примечания. Это может сделать 
ваши образцы более понятными.

```rust
use regex::Regex;

let re = Regex::new(r"(?x)
  (?P<y>\d{4}) # the year, including all Unicode digits
  -
  (?P<m>\d{2}) # the month, including all Unicode digits
  -
  (?P<d>\d{2}) # the day, including all Unicode digits
").unwrap();

let before = "1973-01-05, 1975-08-25 and 1980-10-18";
let after = re.replace_all(before, "$m/$d/$y");
assert_eq!(after, "01/05/1973, 08/25/1975 and 10/18/1980");
```
Если вы хотите сопоставить пробелы в этом режиме, вы по-прежнему можете использовать 
`\s,` `\n,` `\t` и т. д. Для экранирования одного знака пробела вы можете экранировать его 
напрямую с помощью `\ ` , использовать его шестнадцатеричное имя знака `\x20` или временно 
отключить `x` условие, например, `(?-x: )`.


### Пример: одновременное сопоставление нескольких регулярных выражений

Это отображает, как использовать [`RegexSet`] для сопоставления нескольких (возможно, перекрывающихся) регулярных выражений за один проход стога сена:

```rust
use regex::RegexSet;

let set = RegexSet::new(&[
    r"\w+",
    r"\d+",
    r"\pL+",
    r"foo",
    r"bar",
    r"barfoo",
    r"foobar",
]).unwrap();

// Iterate over and collect all of the matches. Each match corresponds to the
// ID of the matching pattern.
let matches: Vec<_> = set.matches("foobar").into_iter().collect();
assert_eq!(matches, vec![0, 2, 3, 4, 6]);

// You can also test whether a particular regex matched:
let matches = set.matches("foobar");
assert!(!matches.matched(5));
assert!(matches.matched(6));
```

# Производительность

В этом разделе кратко обсуждаются некоторые вопросы, связанные со скоростью и использованием ресурсов регулярных выражений.

### Просите только то, что вам нужно

При выполнении поиска с использованием регулярного выражения обычно можно запросить три различных вида сведений:

1.Находит ли регулярное выражение соответствие стогу сена?<br>
2.Где в стоге сена находится соответствие регулярному выражению?<br>
3.Где в стоге сена размещаются все группы захвата?<br>
Вообще говоря, это дополнение могло бы предоставить функцию для ответа только на #3, которая самостоятельно включала бы #1 и #2. 
Однако вычисление местоположения групповых совпадений захвата может быть значительно более затратным, поэтому лучше этого не делать, 
если в этом нет необходимости.

Поэтому спрашивайте только то, что вам нужно. Например, не используйте, [`Regex::find`] если вам нужно только проверить, соответствует ли 
регулярное выражение стогу сена. Вместо этого используйте [`Regex::is_match`] .

### Unicode может влиять на использование памяти и скорость поиска

Это дополнение имеет первоклассную поддержку Unicode и **включено по умолчанию** . 
Во многих случаях дополнительная память, необходимая для его поддержки, будет 
незначительной и обычно не повлияет на скорость поиска. Но может в некоторых случаях.

Что касается использования памяти, влияние Unicode в основном проявляется через 
использование собраний знаков Unicode. Собрания знаков Unicode, как правило, довольно 
большие. Например, значению `\w` по умолчанию соответствует около 140 000 различных знаков. 
Это требует дополнительной памяти и, как правило, замедляет сборку регулярных выражений. 
Хотя значение `\w` вряд ли будет замечено, знак, `\w{100}` например, приведет к довольно большому 
регулярному выражению по умолчанию. Размер значения `\w` значительно больше, чем его исполнение 
только для ASCII, поэтому, если ваши требования удовлетворяются ASCII, вероятно, 
хорошим решением будет использовать ASCII. При использовании `\w` в исполнении только для ASCII -  есть 
несколько способов использования. Все ниже указанные примеры равноценны:

* `[0-9A-Za-z_]`
* `(?-u:\w)`
* `[[:word:]]`
* `[\w&&\p{ascii}]`

Что касается скорости поиска, Unicode, как правило, обрабатывается довольно хорошо, даже при
 использовании больших собраний знаков Unicode. Однако некоторые из более быстрых внутренних 
 движков регулярных выражений не могут обрабатывать утверждение границы слова, поддерживающее Unicode. 
 Поэтому, если вам не нужны утверждения границы слова, поддерживающие Unicode, вы можете рассмотреть 
 возможность использования `(?-u:\b)` вместо `\b`, где первый использует определение знака слова только в виде ASCII.

### Знаки могут ускорить поиск

Это дополнение, как правило, довольно хорошо распознает знаки в образце регулярных выражений 
и использует их для ускорения поиска. Если вообще возможно включить какой-либо знак в ваш 
образец, то это может существенно ускорить поиск. Например, в регулярном выражении `\w+@\w+` движок 
будет искать вхождения `@`, а затем попробует обратное соответствие для `\w+` нахождения начальной позиции.

### Избегайте повторной сборки регулярных выражений, особенно в круговороте.

Сборка одного и того же образца в круговороте является антиобразцом, 
поскольку сборка регулярных выражений обычно требует больших затрат. 
(Это занимает от нескольких микросекунд до нескольких `миллисекунд` в зависимости от размера образца.) 
Сборка сама по себе требует больших затрат, но это также предотвращает оптимизации, которые повторно 
используют выделения памяти внутри движка регулярных выражений.

В Ржавчине иногда может быть сложно передавать регулярные выражения, если они используются внутри вспомогательной функции. 
Вместо этого мы рекомендуем использовать дополнения вроде [`once_cell`] и , [`lazy_static`] чтобы заверять, 
что образцы собираются ровно один раз.

В этом примере показано, как использовать `once_cell`:

[`once_cell`]: https://crates.io/crates/once_cell
[`lazy_static`]: https://crates.io/crates/lazy_static

В этом примере показано, как использовать `once_cell`:

```rust
use {
    once_cell::sync::Lazy,
    regex::Regex,
};

fn some_helper_function(haystack: &str) -> bool {
    static RE: Lazy<Regex> = Lazy::new(|| Regex::new(r"...").unwrap());
    RE.is_match(haystack)
}

fn main() {
    assert!(some_helper_function("abc"));
    assert!(!some_helper_function("ac"));
}
```

В частности, в этом примере регулярное выражение будет собрано при первом использовании. 
При последующих использованиях оно будет повторно использовать ранее построенный `Regex`. 
Обратите внимание, как можно определить `Regex` местно для определенной функции.

### Совместное использование регулярного выражения в нескольких потоках может привести к несоответствиям

Хотя один образец `regex` может свободно использоваться в нескольких потоков одновременно, есть 
небольшая стоимость совмещения, которую необходимо оплатить. Вообще говоря, не следует 
ожидать, что вы это заметите, если только основная задача в каждом потоке не заключается в 
поиске с помощью регулярного выражения , а большинство поисков выполняется на коротких стогах сена. 
В этом случае внутренняя очередь за общие ресурсы может резко возрасти и увеличить задержку, что, 
в свою очередь, может замедлить каждый отдельный поиск.

Эту проблему можно обойти, повторно создав каждое из них `regex` перед отправкой в ​​другой поток. Повторно созданные 
регулярные выражения по-прежнему будут совместно использовать одну и ту же внутреннюю часть собранного 
состояния, доступную только для чтения (с подсчетом ссылок), но каждый поток получит оптимизированный доступ к 
изменяемому пространству, которое используется для выполнения поиска. В общем, это не требует дополнительных 
затрат памяти. Единственной затратой является дополнительная сложность рукописи, необходимая для явного повторного создания 
регулярного выражения. (Если вы совместно используете одно и то же `regex` в нескольких потоках, каждый поток по-прежнему 
получит свое собственное изменяемое пространство, но доступ к этому пространству будет медленнее).

# Unicode

В этом разделе рассматривается, какой вид поддержки Unicode имеет эта библиотека регулярных выражений. Прежде чем показать несколько примеров, мы обобщим соответствующие особенности:

* Это дополнение почти полностью использует «Basic Unicode Support» (Level 1), как указано 
в [Unicode Technical Standard #18][UTS18] . Полные сведения о том, что поддерживается, задокументированы 
в [UNICODE.md] в корне репозитория `regex` crate. В действительности отсутствует поддержка 
«Extended Unicode Support» (Level 2) из ​​UTS#18.
* Верхний уровень [`Regex`] запускает поиск , как будто перебирая каждый из знаков в стоге сена. 
То есть, единицей для сопоставления является один знак.
* [`bytes::Regex`], напротив, позволяет отключить режим Unicode для части всего вашего образца во всех 
случаях. Когда режим Unicode отключен, поиск выполняется так, *как будто* один байт это один знак. То есть, единицей для составления является один байт. (Верхний уровень Regex
также позволяет отключить Unicode и, таким образом, сопоставление производится строго по одному байт за раз, но 
только тогда, когда это не позволяет сопоставить недействительный знак UTF-8.)
* Когда режим Unicode включен (по умолчанию), значение `.` будет соответствовать любому одиночному знаку Unicode, 
даже если оно представлено с использованием нескольких байтов (2-4 байта). Когда режим Unicode отключен (например, `(?-u:.)`), значение `.`
будет соответствовать одному байту во всех случаях.
* Значения `\w`, `\d` и `\s` по умолчанию поддерживают Unicode. Используйте `(?-u:\w)`, `(?-u:\d)` и , `(?-u:\s)` 
чтобы использовать их только для ASCII.
* Границы слова `\b` и `\B` также поддерживают Unicode. Чтобы получить границы слов 
только в ASCII, используйте `(?-u:\b)` и `(?-u:\B)`. Это также применимо к особым утверждениям 
границ слов. (То есть, `\b{start}`, `\b{end}`, `\b{start-half}`, `\b{end-half}`).
*`^` и `$` не распознают Unicode в многострочном режиме. А именно, они распознают только `\n`
(при условии, что режим CRLF не включен), а не какие-либо другие виды разделителей строк, 
определенные Unicode. 
* Поиск без учета заглавных или строчных букв поддерживается Unicode и использует простое преобразование заглавных или строчных букв.
* Общие разделы Unicode, скрипты и многие логические свойства доступны по умолчанию через `\p{property name}` правила писания.
* Во всех случаях совпадения сообщаются с использованием смещений байтов. Или, точнее, смещений кодовых единиц UTF-8. 
Это позволяет индексировать и нарезать стог сена за постоянное время.


[UTS18]: https://unicode.org/reports/tr18/
[UNICODE.md]: https://github.com/rust-lang/regex/blob/master/UNICODE.md

Сами образцы представляются только как последовательность одиночных знаков Unicode. 
Это означает, что вы можете использовать знаки Unicode непосредственно в вашем образце:

```rust
use regex::Regex;

let re = Regex::new(r"(?i)Δ+").unwrap();
let m = re.find("ΔδΔ").unwrap();
assert_eq!((0, 6), (m.start(), m.end()));
// alternatively:
assert_eq!(0..6, m.range());
```

Как отмечено выше, общие разделы Unicode, сценарии, расширения сценариев, возрасты и 
немного булевых свойств доступны как собрания знаков. Например, вы можете сопоставить 
последовательность цифр, греческих или чероки-букв:

```rust
use regex::Regex;

let re = Regex::new(r"[\pN\p{Greek}\p{Cherokee}]+").unwrap();
let m = re.find("abcΔᎠβⅠᏴγδⅡxyz").unwrap();
assert_eq!(3..23, m.range());
```

Хотя эта библиотека не является предназначенной для Unicode, она также поддерживает действия над 
наборами собраний знаков. А именно, можно произвольно вкладывать собрания знаков и выполнять 
над ними действия над наборами. Эти действия над наборами — объединение (по умолчанию), пересечение, 
разность и симметричная разность. Эти действия над наборами, как правило, наиболее полезны с собраниями 
знаков Unicode. Например, чтобы сопоставить любой знак, которая есть как в Greek сценарии, 
так и в Letter общей разделы:

```rust
use regex::Regex;

let re = Regex::new(r"[\p{Greek}&&\pL]+").unwrap();
let subs: Vec<&str> = re.find_iter("ΔδΔ𐅌ΔδΔ").map(|m| m.as_str()).collect();
assert_eq!(subs, vec!["ΔδΔ", "ΔδΔ"]);

// If we just matches on Greek, then all codepoints would match!
let re = Regex::new(r"\p{Greek}+").unwrap();
let subs: Vec<&str> = re.find_iter("ΔδΔ𐅌ΔδΔ").map(|m| m.as_str()).collect();
assert_eq!(subs, vec!["ΔδΔ𐅌ΔδΔ"]);
```

### Отказ от поддержки Unicode

Вид [`bytes::Regex`], который можно использовать для поиска `&[u8]` в стогах сена. 
По умолчанию стога сена обрабатываются как UTF-8, как и в случае с 
основным `Regex` видом. Однако это поведение можно отключить, отключив `u` условие, даже 
если это может привести к сопоставлению с недопустимым исполнением UTF-8. Например, когда `u` 
условие отключено, значение `.` будет соответствовать любому одному байту, вместо любого одиночного знака Unicode, 
который представлен как несколько байт.

Отключение `u` условия также возможно со стандартным видом `&str` на основе - `regex` , но это 
разрешено только там, где поддерживается инвариант UTF-8. Например, `(?-u:\w)` является 
собранием знаков только для ASCII `\w` и является допустимым в `&str` - `Regex`, но `(?-u:\W)` 
будет пытаться сопоставить любой байт , который не находится в `(?-u:\w)`, что, в свою очередь, 
включает байты, которые являются недопустимыми UTF-8. Также как, `(?-u:\xFF)` будет пытаться 
сопоставить необработанный байт `\xFF` (вместо `U+00FF`), который является недопустимым UTF-8 и, 
следовательно, является недопустимым в `&str` регулярных выражениях.

Наконец, поскольку поддержка Unicode требует объединения больших таблиц данных Unicode, 
это дополнение предоставляет ручки для отключения сборки этих таблиц данных, что может быть 
полезно для сокращения двоичного размера и сокращения времени сборки. Подробности о том, как 
это сделать, см. в разделе о функциях дополнения .


# Правила_написания

Правила писания, поддерживаемые в этом дополнении, описаны ниже.

Обратите внимание, что оценщик регулярных выражений и абстрактные правила писания представлены в 
отдельном дополнении, regex-syntax [`regex-syntax`](https://docs.rs/regex-syntax).

### Соответствие одному знаку

<pre class="rust">
.             любой знак, кроме новой строки (включая новую строку с условием s)
[0-9]         любая цифра ASCII
\d            цифра (\p{Nd})
\D            не цифра
\pX           Собрание знаков Unicode, идентифицируемое однобуквенным именем
\p{Greek}     Собрание знаков Unicode (общий раздел или сценарий)
\PX           Отрицательное собрание знаков Unicode, идентифицируемое однобуквенным именем
\P{Greek}     отрицательное собрание знаков Unicode (общий раздел или сценарий)
</pre>

### Виды собраний

<pre class="rust">
[xyz]         Собрание знаков, соответствующее x, y или z (объединение).
[^xyz]        Собрание знаков, соответствующее любому знаку, кроме x, y и z.
[a-z]         Собрание знаков, соответствующее любому знаку в диапазоне az.
[[:alpha:]]   Собрание знаков ASCII ([A-Za-z])
[[:^alpha:]]  Отрицательное собрание знаков ASCII ([^A-Za-z])
[x[^xyz]]     Вложенный/группирующий собрание знаков (соответствует любому знаку, кроме y и z)
[a-y&&xyz]    Пересечение (соответствует x или y)
[0-9&&[^4]]   Вычитание с использованием пересечения и отрицания (соответствует 0-9, кроме 4)
[0-9--4]      Прямое вычитание (соответствует 0-9, кроме 4)
[a-g~~b-h]    Симметричная разность (соответствует только `a` и `h`)
[\[\]]        Экранирование в собраниях знаков (соответствие [ или ])
[a&&b]        Пустое собрание знаков, не соответствующее ничему
</pre>

Любое именованное собрание знаков может появляться внутри заключенного в скобки `[...]` собрания знаков. Например,
 `[\p{Greek}[:digit:]]` соответствует любой цифре ASCII или любом знаке в
  `Greek` сценарии. `[\p{Greek}&&\pL]` соответствует греческим буквам.

Очередность в собраниях знаков, от наиболее обязательных к наименее обязательным:

1. Диапазоны: `[a-cd]` == `[[a-c]d]`
2. Союз: `[ab&&bc]` == `[[ab]&&[bc]]`
3. Пересечение, разность, симметричная разность. Все три имеют равноценную очередность 
и оцениваются слева направо. Например, 
`[\pL--\p{Greek}&&\p{Uppercase}]` == `[[\pL--\p{Greek}]&&\p{Uppercase}]`.
4. Отрицание: `[^a-z&&b]` == `[^[a-z&&b]]`.

### Композиты

<pre class="rust">
xy    конкатенация (x которым следует y))
x|y   чередование (x or y, предпочтительнее x)
</pre>

В этом примере показано, как работает чередование и что означает предпочтение одной ветви в чередовании последующим ветвям.

```
use regex::Regex;

let haystack = "samwise";
// If 'samwise' comes first in our alternation, then it is
// preferred as a match, even if the regex engine could
// technically detect that 'sam' led to a match earlier.
let re = Regex::new(r"samwise|sam").unwrap();
assert_eq!("samwise", re.find(haystack).unwrap().as_str());
// But if 'sam' comes first, then it will match instead.
// In this case, it is impossible for 'samwise' to match
// because 'sam' is a prefix of it.
let re = Regex::new(r"sam|samwise").unwrap();
assert_eq!("sam", re.find(haystack).unwrap().as_str());
```

### Повторения

<pre class="rust">
x*        ноль или более x (greedy)
x+        один или более из x (greedy)
x?        ноль или один из x (greedy)
x*?       ноль или более x (ungreedy/lazy)
x+?       один или несколько x (ungreedy/lazy)
x??       ноль или один из x (ungreedy/lazy)
x{n,m}    не менее nx и не более m x (greedy)
x{n,}     по крайней мере n x (greedy)
x{n}      ровно n x
x{n,m}?   не менее n x и не более m x (ungreedy/lazy)
x{n,}?    как самое наименьшее n x (ungreedy/lazy)
x{n}?     ровно n x
</pre>

### Пустые совпадения

<pre class="rust">
^               начало стога сена (или начало строки в многострочном режиме)
$               конец стога сена (или конец строки в многострочном режиме)
\A              только начало стога сена (даже при включенном многострочном режиме)
\z              только конец стога сена (даже при включенном многострочном режиме)
\b              Граница слова Unicode (\w с одной стороны и \W, \A или \z с другой)
\B              не является границей слова Unicode
\b{start}, \<   граница начала слова Unicode (\W|\A слева, \w справа)
\b{end}, \>     a Unicode end-of-word boundary (\w слева, \W|\z справа))
\b{start-half}  половина границы начала слова Unicode (\W|\A слева)
\b{end-half}    половина границы конца слова Unicode (\W|\z справа)
</pre>

Пустое регулярное выражение является допустимым и соответствует пустой строке. 
Например, пустое регулярное выражение соответствует `abc` позициям `0`, `1` , `2` и `3`. 
При использовании верхнего уровня [`Regex`] на`&str` стогах сена, пустое соответствие, которое разделяет 
знак, обязательно никогда не будет возвращено. Однако такие соответствия 
разрешены при использовании [`bytes::Regex`]. Например:

```rust
let re = regex::Regex::new(r"").unwrap();
let ranges: Vec<_> = re.find_iter("💩").map(|m| m.range()).collect();
assert_eq!(ranges, vec![0..0, 4..4]);

let re = regex::bytes::Regex::new(r"").unwrap();
let ranges: Vec<_> = re.find_iter("💩".as_bytes()).map(|m| m.range()).collect();
assert_eq!(ranges, vec![0..0, 1..1, 2..2, 3..3, 4..4]);
```

Обратите внимание, что пустое регулярное выражение отличается от регулярного выражения, 
которое никогда не может совпасть. Например, регулярное выражение `[a&&b]` — это собрание знаков, 
представляющее пересечение `a` и `b`. Это пересечение пусто, что означает, что собрание знаков пусто. 
Поскольку в пустом наборе ничего нет, `[a&&b]` не соответствует ничему, даже пустой строке.

### Группировка и условия

<pre class="rust">
(exp)          пронумерованная группа захвата (индексируется открывающейся скобкой)
(?P&lt;name&gt;exp)  именованная (также пронумерованная) группа захвата (имена должны быть буквенно-цифровыми)
(?&lt;name&gt;exp)   именованная (также пронумерованная) группа захвата (имена должны быть буквенно-цифровыми)
(?:exp)        незахватывающая группа
(?flags)       установить условия в текущей группе
(?flags:exp)   установить условия для exp (без захвата)
</pre>

Имена групп захвата должны быть любой последовательностью буквенно-цифровых знаков Unicode, в дополнение к
 `.`, `_`, `[` и `]`. Имена должны начинаться либо с `_` ибо с знака буквы. 
 Знаки букв соответствуют свойству `Alphabetic`
Unicode, тогда как числовые знаки соответствуют объединению
`Decimal_Number`, `Letter_Number` и `Other_Number` общих разделов.

Условия — это каждый отдельный знак. Например,  `(?x)` устанавливает условие `x`
и `(?-x)` очищает условие `x`. Несколько условий могут быть установлены или очищены одновременно:
 `(?xy)` устанавливает `x` и `y` условия и`(?x-y)` устанавливает
 `x` условие и очищает  `y` условие.

Все условия по умолчанию отключены, если не указано иное. Они:

<pre class="rust">
i     без учета заглавных или строчных букв: буквы соответствуют как заглавным, так и строчным буквам
m     многострочный режим: ^ и $ соответствуют началу/концу строки
s     разрешают . соответствовать \n
R     включает режим CRLF: когда включен многострочный режим, используется \r\n
U     поменять местами значения x* и x*?
u     поддержка Unicode (включена по умолчанию)
x     подробный режим, игнорирует пробелы и разрешает примечания строк (начинающиеся с `#`)
</pre>

Обратите внимание, что в режиме verbose пробелы опускаются везде, включая собрания знаков. 
Чтобы вставить пробел, используйте его экранированный вид или шестнадцатеричный знак. Например, `\` или `\x20` для пробела ASCII.

Условия можно переключать в образце. Вот пример, который соответствует без учета заглавных или строчных букв для первой части, но с учетом заглавных или строчных букв для второй части:
```rust
use regex::Regex;

let re = Regex::new(r"(?i)a+(?-i)b+").unwrap();
let m = re.find("AaAaAbbBBBb").unwrap();
assert_eq!(m.as_str(), "AaAaAbb");
```

Обратите внимание, что `a+` соответствует либо , `a` либо `A`, но `b+` соответствует только b.

Многострочный режим означает `^`, что `$` теперь совпадения выполняются не только в начале/конце ввода, но и в начале/конце строк:

```
use regex::Regex;

let re = Regex::new(r"(?m)^line \d+").unwrap();
let m = re.find("line one\nline 2\n").unwrap();
assert_eq!(m.as_str(), "line 2");
```

Обратите внимание, что `^` совпадения появляются после новых строк, даже в конце ввода:

```
use regex::Regex;

let re = Regex::new(r"(?m)^").unwrap();
let m = re.find_iter("test\n").last().unwrap();
assert_eq!((m.start(), m.end()), (5, 5));
```

Если включены и режим CRLF, и многострочный режим, то `^` и `$` будет соответствовать как `\r` и `\n`, но никогда не будет соответствовать середине `\r\n`:

```
use regex::Regex;

let re = Regex::new(r"(?mR)^foo$").unwrap();
let m = re.find("\r\nfoo\r\n").unwrap();
assert_eq!(m.as_str(), "foo");
```

Режим Unicode также может быть выборочно отключен, но только тогда, когда результат 
*не будет* соответствовать недопустимому UTF-8. Хорошим примером этого является использование 
границы слова ASCII вместо границы слова Unicode, что может ускорить некоторые поиски регулярных выражений:

```rust
use regex::Regex;

let re = Regex::new(r"(?-u:\b).+(?-u:\b)").unwrap();
let m = re.find("$$abc$$").unwrap();
assert_eq!(m.as_str(), "abc");
```

### Исходы

Обратите внимание, что сюда включены все возможные исходы, даже те, которые задокументированы в другом месте.

<pre class="rust">
\*              знак *, применяется ко всем ASCII, кроме [0-9A-Za-z<>]
\a              колокол (\x07)
\f              подача вида (\x0C)
\t              горизонтальная табуляция
\n              новая строка
\r              возврат каретки
\v              вертикальная табуляция (\x0B)
\A              соответствует началу стога сена
\z              соответствует концу стога сена
\b              утверждение границы слова
\B              отрицание утверждения границы слова
\b{start}, \<   утверждение границы начала слова
\b{end}, \>     утверждение границы конца слова
\b{start-half}  половина утверждения границы начала слова
\b{end-half}    половина утверждения границы конца слова
\123            восьмеричное имя знака, до трех цифр (если включено)
\x7F            шестнадцатеричное имя знака (ровно две цифры)
\x{10FFFF}      любое шестнадцатеричное имя знака, соответствующий матрице Unicode
\u007F          шестнадцатеричное имя знака (ровно четыре цифры)
\u{7F}          любое шестнадцатеричное имя знака, соответствующий матрице Unicode
\U0000007F      шестнадцатеричное имя знака (ровно восемь цифр)
\U{7F}          любое шестнадцатеричное имя знака, соответствующий матрице  Unicode
\p{Letter}      Собрание знаков Unicode
\P{Letter}      отрицательное собрание знаков Unicode
\d, \s, \w      Собрание знаков Perl
\D, \S, \W      отрицательное собрание знаков Perl
</pre>

### Собрания знаков Perl (совместимы с Unicode)

Эти собрания основаны на определениях, приведенных в
[UTS#18](https://www.unicode.org/reports/tr18/#Compatibility_Properties):

<pre class="rust">
\d     цифра (\p{Nd})
\D      не цифра
\s     пробел (\p{White_Space})
\S     не пробел
\w     знак слова (\p{Alphabetic} + \p{M} + \d + \p{Pc} + \p{Join_Control})
\W     не является знаком слова
</pre>

### Собрания знаков ASCII

Эти собрания основаны на определениях, приведенных в
[UTS#18](https://www.unicode.org/reports/tr18/#Compatibility_Properties):

<pre class="rust">
[[:alnum:]]    буквенно-цифровой ([0-9A-Za-z])
[[:alpha:]]    алфавитный ([A-Za-z])
[[:ascii:]]    ASCII-код ([\x00-\x7F])
[[:blank:]]    пусто ([\t ])
[[:cntrl:]]    управление ([\x00-\x1F\x7F])
[[:digit:]]    цифры ([0-9])
[[:graph:]]    графический ([!-~])
[[:lower:]]    строчные буквы ([az])
[[:print:]]    можно распечатать ([ -~])
[[:punct:]]    знаки препинания ([!-/:-@\[-`{-~])
[[:space:]]    пробел ([\t\n\v\f\r ])
[[:upper:]]    заглавные буквы ([AZ])
[[:word:]]     знаки слова ([0-9A-Za-z_])
[[:xdigit:]]   шестнадцатеричная цифра ([0-9A-Fa-f])
</pre>

# Ненадежный_ввод

Это дополнение предназначено для запуска поиска регулярных выражений в ненадежных стогах сена без страха [ReDoS]. 
 Это дополнение также, в определенной степени, поддерживает ненадежные образцы.

[ReDoS]: https://en.wikipedia.org/wiki/ReDoS

Это дополнение отличается от большинства (но не всех) других движков регулярных выражений тем, что он не использует неограниченный 
бэктрекинг для запуска поиска регулярных выражений. В таких случаях обычно нельзя использовать ненадежные образцы *или* ненадежные 
стога сена, поскольку может быть очень сложно узнать, приведет ли определенный образец к катастрофическому бэктрекингу или нет.

Сначала мы обсудим, как это дополнение справляется с недостоверными входными данными, а затем завершим реалистичным обсуждением того, 
как на самом деле выглядит эта практика.

### Сбой

За исключением четко документированных случаев, большинство API в этом дополнении предназначены для того, 
чтобы никогда не было сбоя, независимо от вводимых им входных данных. Например, `Regex::new`,
`Regex::is_match`, `Regex::find` и `Regex::captures` никогда не должны приводить к сбою. То есть API обещает, 
что эти API никогда не приводить к сбою, независимо от вводимых им входных данных. С учетом сказанного, 
движки регулярных выражений — сложные звери, и предоставление полного заверения того, что эти 
API буквально никогда не приводят к сбою, по сути, равноценно заявлению: «В этой библиотеке нет ошибок». 
Это смелое заявление, и на самом деле его нельзя сделать с важным лицом.

Не поймите меня неправильно. Это дополнение тщательно проверен, не только с помощью модульных 
и интеграционных проверок, но и с помощью fuzz-проверок. Например, это дополнение является частью 
проекта OSS-fuzz. Сбои должны быть невероятно редкими, но ошибки могут существовать, и, следовательно, 
возможно возникновение сбоя. Если вам нужно надежное заверение против сбоев, то вам следует обернуть 
вызовы в эту библиотеку с помощью [`std::panic::catch_unwind`].

Также стоит отметить, что эта библиотека *обычно* вызывает сбой, 
когда другие движки регулярных выражений совершают неопределенное 
поведение. Когда происходит неопределенное поведение, ваша программа может 
продолжать работать так, как будто ничего плохого не произошло, но это также может означать, 
что ваша программа открыта для самых худших видов уязвимостей. Напротив, худшее, что может 
вызвать сбой, — это отказ в обслуживании.

[OSS-fuzz project]: https://android.googlesource.com/platform/external/oss-fuzz/+/refs/tags/android-t-preview-1/projects/rust-regex/
[`std::panic::catch_unwind`]: https://doc.rust-lang.org/std/panic/fn.catch_unwind.html

### Ненадежные образцы

Основной способ, которым это дополнение справляется с ними, — это ограничение их размера 
по умолчанию. Ограничение размера можно настроить с помощью [`RegexBuilder::size_limit`]. 
Масль ограничения размера заключается в том, что сборка образца в `regex` не удастся, 
если он станет «слишком большим». А именно, хотя *большинство* ресурсов, потребляемых при 
сборки регулярного выражения, приблизительно соразмерны (хотя и с некоторыми 
высокими постоянными коэффициентами в некоторых случаях, например, с собраниями знаков Unicode) 
длине самого образца, есть одно особое исключение: подсчитанные повторения. А именно, этот образец:

```text
a{5}{5}{5}{5}{5}{5}
```

Равноценен этому образцу:

```text
a{15625}
```

В обоих случаях действительная строка образца довольно мала, но результирующее `regex` 
значение довольно велико. Действительно, как показывает первый образец, недостаточно 
местно ограничить размер каждого повторения, поскольку они могут быть сложены 
таким образом, что это приведет к экспоненциальному росту.

Чтобы обеспечить немного больше контекста, упрощенный вид сборки регулярных 
выражений выглядит следующим образом:

* Строка образца разбирается в упорядоченное представление, называемое AST. 
Подсчитанные повторения не расширяются, и собрания знаков Unicode не ищутся на 
этом этапе. То есть размер AST соразмерен размеру образца с «разумными» 
постоянными множителями. Другими словами, можно разумно ограничить память, 
используемую AST, ограничив длину строки образца.
* AST транслируется в HIR. Подсчитанные повторения все еще не расширяются на этом этапе, 
но собрания знаков Unicode встроены в HIR. Использование памяти HIR все еще 
соразмерно длине исходной строки образца, но постоянные обстоятельства — в 
основном из-за собраний знаков Unicode — могут быть довольно высокими. 
Тем не менее, память, используемая HIR, может быть разумно ограничена 
путем ограничения длины строки образца.
* HIR собирается в [Thompson NFA]. Это этап, на котором что-то вроде
`\w{5}` переписывается в `\w\w\w\w\w`. Таким образом, это этап, на котором
 [`RegexBuilder::size_limit`] применяется. Если NFA превышает настроенный размер, 
 то этот этап завершится неудачей.

[Thompson NFA]: https://en.wikipedia.org/wiki/Thompson%27s_construction

Ограничение размера помогает избежать двух различных видов чрезмерного использования ресурсов:

* Это позволяет избежать экспоненциального использования памяти в зависимости от размера строки образца.
* Это позволяет избежать длительного времени поиска. Это будет обсуждаться более подробно в следующем разделе, 
но худшее время поиска зависит от размера регулярного выражения. Поэтому ограничение регулярных выражений 
разумным размером также является способом сохранения разумного времени поиска.

Наконец, стоит отметить, что сборка регулярных выражений обязательно займет
 `O(m)` время в худшем случае, где `m` соразмерно размеру регулярных выражений. 
 Размер регулярных выражений здесь указан *после того*, как подсчитанные повторения были расширены.

**Совет тем, кто использует ненадежные регулярные выражения**: ограничьте длину образца 
чем-то небольшим и расширяйте его по мере необходимости. Настрой [`RegexBuilder::size_limit`]
на что-то небольшое и затем расширяйте его по мере необходимости.

### Ненадежные стога сена

Основной способ, которым это дополнение защищает от слишком долгого поиска, — 
это использование алгоритмов, которые заверяют  `O(m * n)` наихудшие временные и 
пространственные ограничения. А именно:

* `m` соразмерен размеру регулярного выражения, где размер регулярного 
выражения включает расширение всех подсчитанных повторений. (См. предыдущий раздел о ненадежных образцах.)
* `n` соразмерен длине стога сена в байтах.

Другими словами, если вы считаете, `m` что является константой (например, образец регулярного выражения 
является знаком в исходной рукописи), то можно сказать, что поиск выполняется за «линейное время». Или, что то же самое, 
«линейное время относительно размера стога сена».

Но `m` обстоятельство здесь важен, чтобы его не игнорировать. Если регулярное выражение особенно большое, 
время поиска может стать довольно медленным. Вот почему, отчасти, [`RegexBuilder::size_limit`] существует.

**Совет тем, кто ищет ненадежные стога сена**: пока ваши регулярные выражения не огромны, 
вы должны ожидать, что сможете искать ненадежные стога сена без страха. Если вы не уверены, 
вам следует провести бенчмаркинг. В отличие от движков обратного отслеживания, если ваше 
регулярное выражение настолько велико, что, скорее всего, приведет к медленному поиску, 
это, вероятно, то, что вы сможете наблюдать независимо от того, из чего состоит стог сена.

### Итерация по совпадениям

Одна вещь, которую, возможно, легко упустить из виду, заключается в том, что наихудшая 
временная сложность ограничения `O(m * n)` применяется к таким способам, как [`Regex::is_match`],
[`Regex::find`] и [`Regex::captures`]. Она **не** применяется к
[`Regex::find_iter`] или [`Regex::captures_iter`]. А именно, поскольку итерация по всем совпадениям 
может выполнить много поисков, а каждый поиск может сканировать весь стог сена, наихудшая временная 
сложность для повторителей составляет `O(m * n^2)`.

Одним из примеров того, где это происходит, является случай, когда образец состоит из чередования, 
где более ранняя ветвь чередования требует сканирования всего стога сена только для того, чтобы обнаружить, 
что совпадений нет. Также требуется, чтобы более поздняя ветвь чередования совпала в начале поиска. 
Например, рассмотрим образец  `.*[^A-Z]|[A-Z]` и стог сена `AAAAA`. TПервый поиск будет сканировать до конца в поисках совпадений, 
 `.*[^A-Z]` хотя конечный автомат (как в этом дополнении) знает, что `[A-Z]` уже совпал с первым знаком стога сена. Это связано 
 с жадной природой поиска регулярных выражений. Этот первый поиск сообщит о совпадении в первом
`A` только после сканирования до конца, чтобы обнаружить, что других совпадений не существует. Затем следующий 
поиск начинается со второго `A` и поведение повторяется.

Избежать этого невозможно. Это означает, что если и образцы, и стога сена не являются доверенными, 
и вы перебираете все совпадения, вы подвержены наихудшей квадратичной временной сложности. Один из 
возможных способов смягчить это — спуститься на нижний уровень  `regex-automata` дополнения и использовать его
`meta::Regex` API повторителя. Там вы можете настроить поиск на работу в «самом раннем» режиме, передав
`Input::new(haystack).earliest(true)` в `meta::Regex::find_iter` (например). Включая этот режим, вы 
отказываетесь от обычной семантики жадного соответствия поиска регулярных выражений и вместо этого 
просите движок регулярных выражений немедленно остановиться, как только будет найдено совпадение. 
Включение этого режима, таким образом, восстановит `O(m * n)` ограничение временной сложности наихудшего 
случая, но за счет другой семантики.

### Недостоверные данные на практике

Хотя предоставление `O(m * n)` ограничения по времени на худший случай для всех поисков имеет большое значение для предотвращения [ReDoS], 
это не означает, что каждый поиск, который вы можете запустить, будет завершен без сжигания процессорного времени. В общем, есть несколько 
способов, которыми `m * n` ограничение по времени все еще может вас укусить:

* Вы ищете исключительно длинный стог сена. Как бы вы его ни разрезали, более длинный стог сена займет больше времени для поиска. 
Это дополнение часто может очень быстро работать даже с длинными стогами сена из-за его буквальных оптимизаций, но они доступны не 
для всех регулярных выражений.
* Собрания знаков Unicode могут в некоторых случаях приводить к довольно медленному поиску. 
Это особенно актуально, когда они сочетаются с подсчитанными повторениями. Хотя ограничение размера 
регулярных выражений, указанное выше, защитит вас от самых вопиющих случаев, ограничение размера по 
умолчанию все еще допускает довольно большие регулярные выражения, которые могут выполняться медленнее, 
чем можно было бы ожидать.
* В то время как процедуры вида [`Regex::find`] и [`Regex::captures`] обеспечивают худшее  `O(m * n)` время поиска, процедуры вида
 [`Regex::find_iter`] и [`Regex::captures_iter`] на самом деле имеют худшее  `O(m * n^2)` время поиска. 
 Это происходит потому, что  `find_iter` запускает много поисков, и каждый поиск занимает худшее
`O(m * n)` время. Таким образом, итерация всех совпадений в стоге сена имеет худший случай
`O(m * n^2)`.Хорошим примером образца, который отображает это, является
`(?:A+){1000}|` или даже  `.*[^A-Z]|[A-Z]`.

В целом, ненадежные стога сена легче переварить, чем ненадежные образцы. Ненадежные образцы дают 
вызывающей стороне гораздо больше контроля над производительностью поиска. Во многих случаях поиск 
по регулярному выражению на самом деле будет выполняться за среднее `O(n)` время (т. е. независимо от 
размера регулярного выражения), но в целом это не может быть обеспечено. Таким образом, разрешение 
ненадежных образцов означает, что ваша единственная линия защиты — установить ограничение на то, 
насколько большим `m` (и, возможно, также `n`) может быть в `O(m * n)`. `n` ограничивается 
простой проверкой длины стога сена, в то время как `m` ограничивается как применением ограничения 
к длине образца , так и ограничением на собранный размер регулярного выражения через
[`RegexBuilder::size_limit`].

Стоит повторить: если вы принимаете ненадежные образцы, было бы неплохо начать с консервативных 
ограничений на `m` и `n`, а затем осторожно увеличивать их по мере необходимости.

# Возможности_дополнения

По умолчанию это дополнение изо всех сил старается сделать сопоставление регулярных выражений как 
можно более быстрым и правильным. Это означает, что много рукописи посвящено производительности, 
обработке данных Unicode и самим данным Unicode. В целом, это приводит к большему количеству 
зависимостей, большим двоичным файлам и более длительному времени сборки. Этот компромисс может 
быть неподходящим во всех случаях, и действительно, даже когда все функции Unicode и производительности 
отключены, все равно остается вполне работоспособный движок регулярных выражений, который будет хорошо 
работать во многих случаях. (Обратите внимание, что код не может быть произвольно сокращена, и по этой 
причине дополнение [`regex-lite`](https://docs.rs/regex-lite) существует, чтобы обеспечить еще более 
минимальный опыт, вырезая Unicode и производительность, но при этом сохраняя линейную границу времени поиска.)

Это дополнение предоставляет ряд функций для управления этим компромиссом. Некоторые из этих функций строго 
ориентированы на производительность, так что их отключение не приведет к потере функциональности, 
но может привести к ухудшению производительности. Другие функции, такие как те, которые контролируют 
наличие или отсутствие данных Unicode, могут привести к потере функциональности. Например, если отключить функцию
`unicode-case` (описанную ниже), то сборка регулярного выражения `(?i)a`
не удастся, поскольку нечувствительность к заглавным или строчным буквам в Unicode включена по умолчанию. 
Вместо этого вызывающие должны использовать `(?i-u)a` для отключения сворачивания заглавных или строчных букв Unicode. 
Иными словами, включение или отключение любой из функций ниже может только добавлять или вычитать из 
общего набора допустимых регулярных выражений. Включение или отключение функции никогда не изменит 
семантику соответствия регулярного выражения.

Большинство функций ниже включены по умолчанию. Функции, которые не включены по умолчанию, отмечены.

### Особенности экосистемы

* **std** -
   при включении это приведет `regex` к использованию стандартной библиотеки. 
   С точки зрения API, `std` заставляет виды ошибок использовать `std::error::Error`
  черту. Включение `std`также приведет к оптимизации производительности, включая SIMD и более быстрые примитивы согласования. 
  В частности, **отключение `std` функции приведет к использованию спин-блокировок**. 
  Чтобы использовать движок регулярных выражений без `std` спин-блокировок и без них, вам нужно будет перейти к 
  [`regex-automata`](https://docs.rs/regex-automata) дополнению.
* **logging** -
   При включении `log`` дополнение используется для отправки сообщений о сборке регулярных 
   выражений и стратегиях поиска ** По умолчанию отключено **. Обычно это полезно только для тех, 
   кто работает над внутренними компонентами этого дополнения, но может быть полезно, 
   если вы занимаетесь хакингом производительно

### Эксплуатационные характеристики

* **perf** -
 Включает все функции, связанные с производительностью, за исключением `perf-dfa-full`. 
 Эта функция включена по умолчанию и предназначена для охвата всех разумных функций, 
 которые повышают производительность, даже если в будущем будут добавлены дополнительные функции.
* **perf-dfa** -
  позволяет использовать ленивый DFA для сопоставления. Ленивый DFA используется для сборки 
  частей регулярного выражения в очень быстрый DFA по мере необходимости. Это может привести к 
  существенному ускорению, обычно на порядок величины для больших стогов сена. 
  Ленивый DFA не вносит никаких новых зависимостей, но может увеличить время сборки.
* **perf-dfa-full** -
 позволяет использовать полный DFA для сопоставления. Полные DFA проблематичны, поскольку 
 имеют худшее `O(2^n)` время построения. По этой причине, когда эта функция включена, 
 полные DFA используются только для очень маленьких регулярных выражений, а во время 
 определения используется очень маленькая граница пространства, чтобы избежать взрыва DFA. 
 Эта функция не включена по умолчанию, даже как часть
  `perf`, поскольку она приводит к довольно значительному увеличению двоичного размера 
  и времени сборки. Она может привести к более быстрому времени поиска, но они, как 
  правило, более скромны и ограничены не-Unicode регулярными выражениями.
* **perf-onepass** -
 Позволяет использовать однопроходный DFA для извлечения позиций групп захвата. 
 Эта оптимизация применяется к подмножеству определенных видов NFA и представляет 
 собой самый быстрый движок в этом дополнении для работы с группами захвата.
* **perf-backtrack** -
   позволяет использовать ограниченный алгоритм обратного отслеживания для извлечения позиций
    групп захвата. Обычно он находится между самым медленным движком (PikeVM) и самым быстрым 
    движком (однопроходный DFA) для извлечения групп захвата. Он используется всякий раз, 
    когда регулярное выражение не является однопроходным и достаточно мало.
* **perf-inline** -
  позволяет использовать агрессивное встраивание внутри процедур сопоставления. 
  Это снижает накладные расходы каждого сопоставления. Однако агрессивное встраивание увеличивает время сборки и размер двоичной рукописи.
* **perf-literal** -
   Позволяет использовать буквальные оптимизации для ускорения совпадений. 
   В некоторых случаях буквальные оптимизации могут привести к ускорению на несколько порядков. 
   Отключение этого параметра отменяет зависимости `aho-corasick` и `memchr`.
* **perf-cache** -
  эта функция использовалась для включения более быстрого внутреннего кэша за счет использования дополнительных зависимостей, 
  но теперь это не вариант. Быстрый внутренний кэш теперь используется безусловно без дополнительных зависимостей. Это может измениться в будущем.

### Возможности Unicode

* **unicode** -
  Включает все функции Unicode. Эта функция включена по умолчанию и всегда будет охватывать все функции Unicode, даже если в будущем будут добавлены новые.
* **unicode-age** -
 Предоставьте данные для
  [ свойства Unicode `Age``](https://www.unicode.org/reports/tr44/tr44-24.html#Character_Age).
  Это позволяет использовать собрания, например, `\p{Age:6.0}`
  для ссылки на все знаки, впервые представленные в Unicode 6.0
* **unicode-bool** -
   предоставляет данные для многочисленных логических свойств Unicode. Полный список здесь не включен, 
   но содержит такие свойства, как  `Alphabetic`, `Emoji`,
  `Lowercase`, `Math`, `Uppercase` and `White_Space`.
* **unicode-case** -
  предоставление данных для сопоставления без учета заглавных или строчных букв с использованием
  [спецификации «простых свободных сопоставлений» Unicode ](https://www.unicode.org/reports/tr18/#Simple_Loose_Matches).
* **unicode-gencat** -
  Предоставьте данные для
  [общих разделов Unicode](https://www.unicode.org/reports/tr44/tr44-24.html#General_Category_Values).
  Это включает, но не ограничивается, `Decimal_Number`, `Letter`,
  `Math_Symbol`, `Number` и `Punctuation`.
* **unicode-perl** -
  Предоставьте данные для поддержки собраний знаков Perl, поддерживающих Unicode, соответствующих
   `\w`, `\s` and `\d`. Это также необходимо для использования утверждений границ слов, 
   поддерживающих Unicode. Обратите внимание, что если эта функция отключена, собрания знаков 
   `\s` and `\d` по-прежнему доступны, если включены функции и соответственно
  `unicode-bool` и `unicode-gencat`.
* **unicode-script** -
  Предоставьте данные для
  [скриптов Unicode и расширений скриптов](https://www.unicode.org/reports/tr24/).
  Это включает, но не ограничивается, `Arabic`, `Cyrillic`, `Hebrew`,
  `Latin` и `Thai`.
* **unicode-segment** -
  Предоставьте данные, необходимые для предоставления свойств, используемых для использования
  [алгоритмов сегментации текста Unicode](https://www.unicode.org/reports/tr29/).
   Это позволяет использовать такие собрания, как `\p{gcb=Extend}`, `\p{wb=Katakana}` и
  `\p{sb=ATerm}`.

# Другие_дополнения

Это дополнение имеет две обязательные зависимости и несколько необязательных зависимостей. 
В этом разделе они кратко описаны с целью повышения осведомленности о том, как различные 
компоненты этого дополнения могут использоваться независимо.

Для движка регулярных выражений довольно необычно иметь зависимости, поскольку большинство 
библиотек регулярных выражений являются самодостаточными единицами без зависимостей, кроме 
стандартной библиотеки определенной среды. Действительно, для других также как оптимизированных
 движков регулярных выражений большая часть или вся рукопись в зависимостях этого дополнения обычно были бы 
 просто неразделимыми или связанными частями самого дополнения. Но поскольку Ржавчина и его инструментальная 
 экосистема делают использование зависимостей таким простым, имело смысл потратить некоторые усилия 
 на разделение частей этого дополнения и сделать их независимо полезными.

Здесь мы лишь кратко описываем каждое дополнение.

* [`regex-lite`](https://docs.rs/regex-lite) не является зависимостью `regex`,
 а скорее автономной упрощенной версией с нулевой зависимостью regex, 
 которая отдает очередность времени сборки и размеру двоичной рукописи. 
 Взамен он избегает поддержки и производительности Unicode. Его семантика 
 соответствия максимально идентична дополнению regex, а для поддерживаемых 
 им вещей его API идентичны API в этом дополнении. Другими словами, для многих 
 случаев использования это замена.
* [`regex-syntax`](https://docs.rs/regex-syntax)предоставляет парсер регулярных выражений через
 `Ast` и `Hir` виды. Он также предоставляет процедуры для извлечения знаков из образца. Люди 
 могут использовать это дополнение для анализа или даже для создания собственного движка регулярных 
 выражений, не беспокоясь о написании парсера.
* [`regex-automata`](https://docs.rs/regex-automata) предоставляет сами движки регулярных выражений. 
Одним из недостатков движков регулярных выражений на основе конечных автоматов является то, что им 
часто требуется несколько внутренних движков, чтобы на практике иметь схожую или лучшую производительность, 
чем движок с неограниченным бэктрекингом.`regex-automata`
 в частности, предоставляет публичные API для PikeVM, ограниченного бэктрекера, однопроходного DFA, 
 ленивого DFA, полностью собранного DFA и движка метарегулярных выражений, который объединяет 
 их все вместе. Он также имеет собственную поддержку нескольких образцов и предоставляет способ 
 сборки и сериализации полных DFA, чтобы их можно было загружать и искать в среде no-std no-alloc.  `regex-automata` 
 сам по себе даже не имеет обязательной зависимости от `regex-syntax`!
* [`memchr`](https://docs.rs/memchr) предоставляет низкоуровневые векторизованные процедуры 
SIMD для быстрого поиска местоположения отдельных байтов или даже подстрок в стоге сена. 
Другими словами, он предоставляет быстрые процедуры `memchr` и `memmem`. Они используются этим дополнением в знаковых оптимизациях.
* [`aho-corasick`](https://docs.rs/aho-corasick) обеспечивает поиск по нескольким подстрокам. 
Он также обеспечивает векторизованные процедуры SIMD в случае, когда количество подстрок для 
поиска относительно невелико `regex` Дополнение также использует это для знаковых оптимизаций.
*/

#![no_std]
#![deny(missing_docs)]
#![cfg_attr(feature = "pattern", feature(pattern))]
#![warn(missing_debug_implementations)]

#[cfg(doctest)]
doc_comment::doctest!("../README.md");

extern crate alloc;
#[cfg(any(test, feature = "std"))]
extern crate std;

pub use crate::error::Error;

pub use crate::{builders::string::*, regex::string::*, regexset::string::*};

mod builders;
pub mod bytes;
mod error;
mod find_byte;
#[cfg(feature = "pattern")]
mod pattern;
mod regex;
mod regexset;

/// Экранирует все метазнаки регулярных выражений в `pattern`.
///
/// The string returned may be safely used as a literal in a regular
/// expression.
pub fn escape(pattern: &str) -> alloc::string::String {
    regex_syntax::escape(pattern)
}
